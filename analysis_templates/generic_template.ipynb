{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhpNHATzvqUTgmVuDnfvbe"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwj52M8s6yuZ"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# PART 1: SETUP AND IMPORTS\n",
        "# ==========================================\n",
        "\n",
        "# Import necessary libraries for data manipulation and visualization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# Set seed\n",
        "np.random.seed(123)\n",
        "\n",
        "# Set visual styles for plots to make them look professional\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (10, 6)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PART 2: LOADING DATA\n",
        "# ==========================================\n",
        "\n",
        "# dynamic way to find the Desktop path so I don't have to hardcode my username\n",
        "desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
        "\n",
        "# Replace 'my_data.csv' with the actual file name\n",
        "filename = 'my_data.csv'\n",
        "file_path = os.path.join(desktop_path, filename)\n",
        "\n",
        "# Load the data\n",
        "# Note: If using Excel, change to pd.read_excel(file_path)\n",
        "try:\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(f\"Successfully loaded {filename}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: File not found. Check the filename and ensure it's on the Desktop.\")"
      ],
      "metadata": {
        "id": "Cum0pne864AH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PART 3: INITIAL INSPECTION (The \"Sanity Check\")\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n--- Shape of the Data ---\")\n",
        "# checking how many rows and columns I'm working with\n",
        "print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")\n",
        "\n",
        "print(\"\\n--- First 5 Rows (Head) ---\")\n",
        "# taking a look at the top of the file to see if headers loaded correctly\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\n--- Last 5 Rows (Tail) ---\")\n",
        "# checking the bottom to make sure there's no garbage footer data\n",
        "print(df.tail())\n",
        "\n",
        "print(\"\\n--- Column Names ---\")\n",
        "# getting a list of all variables\n",
        "print(df.columns.tolist())\n",
        "\n",
        "print(\"\\n--- Data Types and Non-Null Counts ---\")\n",
        "# this is crucial to see if numbers are being read as text (objects)\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "VqB2xFf1659o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PART 4: DATA CLEANING CHECKS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n--- Duplicate Rows ---\")\n",
        "# checking if there are fully duplicated rows which might skew results\n",
        "duplicates = df.duplicated().sum()\n",
        "print(f\"Number of duplicate rows: {duplicates}\")\n",
        "\n",
        "print(\"\\n--- Missing Values ---\")\n",
        "# counting nulls per column to see where the data quality issues are\n",
        "missing_values = df.isnull().sum()\n",
        "print(missing_values[missing_values > 0]) # only showing columns with missing data\n",
        "\n",
        "# Visualization: Heatmap of missing values\n",
        "# simple way to see if missingness is random or structural\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
        "plt.title('Visual Map of Missing Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2XBMD4re67iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PART 5: SUMMARY STATISTICS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n--- Numerical Summary ---\")\n",
        "# basic stats: mean, median (50%), min, max, std dev\n",
        "print(df.describe().T) # Transposing (.T) makes it easier to read if there are many columns\n",
        "\n",
        "print(\"\\n--- Categorical Summary ---\")\n",
        "# summary for non-numeric columns (unique counts, top occurring values)\n",
        "# we include 'O' (Object) to target strings\n",
        "try:\n",
        "    print(df.describe(include=['O']).T)\n",
        "except ValueError:\n",
        "    print(\"No categorical columns found.\")"
      ],
      "metadata": {
        "id": "LEt0xOVM69aM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PART 6: DISTRIBUTION & VISUALIZATION\n",
        "# ==========================================\n",
        "\n",
        "# 1. Histograms for all Numerical Columns\n",
        "# This helps me spot normal distributions vs skewed data\n",
        "# select only numeric columns to avoid errors\n",
        "numeric_df = df.select_dtypes(include=[np.number])\n",
        "\n",
        "if not numeric_df.empty:\n",
        "    numeric_df.hist(bins=30, figsize=(15, 10), layout=(4, 4))\n",
        "    plt.suptitle('Distribution of Numerical Variables')\n",
        "    plt.show()\n",
        "\n",
        "# 2. Boxplots for Outlier Detection\n",
        "# Good for seeing the spread and spotting dots outside the whiskers (outliers)\n",
        "for column in numeric_df.columns:\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    sns.boxplot(x=df[column])\n",
        "    plt.title(f'Boxplot of {column}')\n",
        "    plt.show()\n",
        "\n",
        "# 3. Correlation Matrix (Heatmap)\n",
        "# Checking how variables relate to each other.\n",
        "# 1 = perfect positive correlation, -1 = perfect negative correlation\n",
        "if len(numeric_df.columns) > 1:\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    correlation_matrix = numeric_df.corr()\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "    plt.title('Correlation Heatmap')\n",
        "    plt.show()\n",
        "\n",
        "# 4. Pairplot\n",
        "# Scatter plots of every numeric variable against every other numeric variable\n",
        "# This is heavy on performance but great for spotting patterns immediately\n",
        "if len(numeric_df.columns) <= 10: # Limiting to 10 cols to prevent crashing\n",
        "    sns.pairplot(df.select_dtypes(include=[np.number]).dropna())\n",
        "    plt.title('Pairwise Relationships')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Skipping pairplot: Too many columns.\")"
      ],
      "metadata": {
        "id": "cpGuP2ln6-6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# PART 7: CATEGORICAL ANALYSIS\n",
        "# ==========================================\n",
        "\n",
        "# analyzing the frequency of categories in text columns\n",
        "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "for col in categorical_cols:\n",
        "    # check if there are too many unique values (like Names or IDs) to plot\n",
        "    if df[col].nunique() < 20:\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        sns.countplot(y=df[col], order=df[col].value_counts().index)\n",
        "        plt.title(f'Count of Categories in {col}')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"\\nSkipping plot for {col}: Too many unique values ({df[col].nunique()})\")"
      ],
      "metadata": {
        "id": "a1pgn6iS7BVr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
